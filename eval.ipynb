{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Evals Workshop\n",
    "# [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/altryne/llm-evals-workshop/blob/main/eval.ipynb) [![Weights & Biases](https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-gradient.svg)](https://wandb.ai)\n",
    "\n",
    "This notebook demonstrates how to create, run and track LLM evaluations using [W&B Weave](https://wandb.ai/site/weave). We'll explore different evaluation techniques and how to analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Installing packages\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Packages installed\n"
     ]
    }
   ],
   "source": [
    "# Install and read in required packages, plus create an anthropic client.\n",
    "try:\n",
    "    import google.colab\n",
    "    !git clone --branch main https://github.com/altryne/llm-evals-workshop\n",
    "    %cd llm-evals-workshop\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "print('‚è≥ Installing packages')\n",
    "%pip install uv #TODO: alex figure this out\n",
    "%uv pip install -q weave gradio set-env-colab-kaggle-dotenv tqdm ipywidgets requests openai google-generativeai\n",
    "print('‚úÖ Packages installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weave version 0.51.27 is available!  To upgrade, please run:\n",
      " $ pip install weave --upgrade\n",
      "Logged in as Weights & Biases user: altryne.\n",
      "View Weave data at https://wandb.ai/thursdai/evals-workshop/weave\n",
      "üì¶ Published to https://wandb.ai/thursdai/evals-workshop/weave/objects/doomer_or_boomer/versions/MfppDkza1qvK772eNZWIU1XwwZbtwGQ8UQWWEcyZlfc\n"
     ]
    }
   ],
   "source": [
    "%load_ext gradio\n",
    "import gradio as gr\n",
    "from set_env import set_env\n",
    "import json\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from datetime import datetime\n",
    "import random\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import weave\n",
    "from weave.flow.annotation_spec import AnnotationSpec\n",
    "\n",
    "load_dotenv()\n",
    "set_env(\"WANDB_API_KEY\")\n",
    "set_env(\"OPENAI_API_KEY\")\n",
    "set_env(\"GEMINI_API_KEY\")\n",
    "\n",
    "# initialize weave\n",
    "weave_api = weave.init('evals-workshop')\n",
    "# initialize a basic annotation in this project\n",
    "annotation = weave.publish(AnnotationSpec(\n",
    "    name=\"Doomer or Boomer\",\n",
    "    description=\"Doomer or Boomer or Neither\",\n",
    "    field_schema={\n",
    "        \"type\": \"string\",\n",
    "        \"enum\": [\"Doomer\", \"Boomer\", \"Neither\"],\n",
    "    },\n",
    "), \"doomer_or_boomer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Load the Jinja2 environment\n",
    "env = Environment(loader=FileSystemLoader('templates'))\n",
    "template = env.get_template('post.html.jinja')\n",
    "\n",
    "# Load replies data\n",
    "def load_replies():\n",
    "    replies = []\n",
    "    # Load replies from both files\n",
    "    with open('data/replies_alpin.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        replies.extend(data['thread']['replies'])\n",
    "    with open('data/replies_daniel.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        replies.extend(data['thread']['replies'])\n",
    "    return replies\n",
    "\n",
    "@weave.op\n",
    "def analyze_post_sentiment(text):\n",
    "    # Prompt for OpenAI to analyze the sentiment\n",
    "    prompt = \"Analyze the following Bluesky post and determine if the author is a [Doomer, Boomer, or Neither]\"\n",
    "\n",
    "    # TODO: Add some more context to the prompt\n",
    "    # prompt = f\"\"\"Analyze the following Bluesky post and determine if the author is a:\n",
    "    # - DOOMER (someone who hates AI and uses derogatory language)\n",
    "    # - BOOMER (someone who doesn't understand AI and asks to remove their data)\n",
    "    # - NEITHER (neutral or positive response)\n",
    "    \n",
    "    # Post: {text}\n",
    "    \n",
    "    # Respond with just one word (DOOMER, BOOMER, or NEITHER) followed by a brief explanation.\n",
    "    # \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    current_call = weave.require_current_call()\n",
    "    weave_call_id = current_call.id\n",
    "    \n",
    "    return response.choices[0].message.content, weave_call_id\n",
    "\n",
    "def get_random_post_and_analyze():\n",
    "    replies = load_replies()\n",
    "    post = random.choice(replies)\n",
    "    \n",
    "    # Format the post data for the template\n",
    "    created_at = datetime.fromisoformat(post['post']['record']['createdAt'].replace('Z', '+00:00'))\n",
    "    formatted_date = created_at.strftime('%b %d, %Y, %I:%M %p')\n",
    "    \n",
    "    # Convert AT URI to bsky.app URL\n",
    "    at_uri = post['post']['uri']\n",
    "    _, _, author_did, _, post_id = at_uri.split('/')\n",
    "    post_url = f\"https://bsky.app/profile/{post['post']['author']['handle']}/post/{post_id}\"\n",
    "    \n",
    "    # Analyze the post\n",
    "    analysis, weave_call_id = analyze_post_sentiment(post['post']['record']['text'])\n",
    "    \n",
    "    post_data = {\n",
    "        'author': post['post']['author'],\n",
    "        'created_at': formatted_date,\n",
    "        'text': post['post']['record']['text'],\n",
    "        'like_count': post['post'].get('likeCount', 0),\n",
    "        'repost_count': post['post'].get('repostCount', 0),\n",
    "        'has_image': False,\n",
    "        'post_url': post_url\n",
    "    }\n",
    "    \n",
    "    return template.render(**post_data), analysis, weave_call_id\n",
    "\n",
    "\n",
    "def submit_feedback(user_selection, weave_call_id):\n",
    "    \"\"\"\n",
    "    Example function that could send user feedback (the user_selection)\n",
    "    and the weave_call_id to your Weave (or any other) API.\n",
    "    \"\"\"\n",
    "    call = weave_api.get_call(weave_call_id)\n",
    "    # print(call)\n",
    "    # print(\"user_selection\", user_selection)\n",
    "    # resp = call.feedback.add('annotation.doomer_or_boomer', {\"value\": user_selection})\n",
    "    # print(type(resp))\n",
    "\n",
    "    resp = weave_api.server.feedback_create(\n",
    "        {\n",
    "            \"project_id\": weave_api._project_id(),\n",
    "            \"weave_ref\": call.ref.uri(),\n",
    "            \"feedback_type\": \"wandb.annotation.doomer_or_boomer\",\n",
    "            \"annotation_ref\": annotation.uri(),\n",
    "            \"payload\": {\"value\": user_selection},\n",
    "        }\n",
    "    )\n",
    "    print(resp)\n",
    "    # Just returning a quick debug message for now:\n",
    "    return f\"Feedback sent for call {weave_call_id} with user selection: {user_selection}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/thursdai/evals-workshop/r/call/01943d3b-de19-7bc0-972a-b8c8c9485bfc\n",
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/thursdai/evals-workshop/r/call/01943d3b-eafe-7bf1-a6b7-12a83c407c19\n",
      "üç© https://wandb.ai/thursdai/evals-workshop/r/call/01943d3c-0a96-7773-9ff1-3ba87753a3ff\n",
      "id='01943d3c-26ee-72e0-99de-d4f2bec19023' created_at=datetime.datetime(2025, 1, 6, 20, 8, 59, 886431, tzinfo=TzInfo(UTC)) wb_user_id='VXNlcjoxNzQ4MTAx' payload={}\n",
      "üç© https://wandb.ai/thursdai/evals-workshop/r/call/01943d3c-2505-7332-b093-906e816eb28a\n",
      "üç© https://wandb.ai/thursdai/evals-workshop/r/call/01943d3c-2c9a-7d93-8195-58162f8e9e71\n",
      "id='01943d3c-5c5b-7b42-9eab-4741ad409de8' created_at=datetime.datetime(2025, 1, 6, 20, 9, 13, 563847, tzinfo=TzInfo(UTC)) wb_user_id='VXNlcjoxNzQ4MTAx' payload={}\n",
      "üç© https://wandb.ai/thursdai/evals-workshop/r/call/01943d3c-5a8f-7c71-af6b-a214ff695b5c\n",
      "üç© https://wandb.ai/thursdai/evals-workshop/r/call/01943d3c-71d6-7df2-94b3-3e8f68565857\n",
      "id='01943d3c-8754-7320-9a85-284212f9425b' created_at=datetime.datetime(2025, 1, 6, 20, 9, 24, 564246, tzinfo=TzInfo(UTC)) wb_user_id='VXNlcjoxNzQ4MTAx' payload={}\n",
      "üç© https://wandb.ai/thursdai/evals-workshop/r/call/01943d3c-84f4-7050-99bf-18687cc44717\n"
     ]
    }
   ],
   "source": [
    "# %%blocks\n",
    "# Create a Gradio Blocks app\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    # Add a title and description\n",
    "    gr.Markdown(\"# ü¶ã Doomer or Boomer\")\n",
    "    gr.Markdown(\"\"\"\n",
    "    Our AI analyzes bluesky replies and posts to determine if the author is a doomer or a boomer.  \n",
    "    Source of data: Replies to a post by a BlueSky user that compiled a dataset of posts, which went viral and created a lot of noise on BlueSky.  \n",
    "    `Doomer`: Someone who hates AI, and uses derogatory language towards the author of the post.  \n",
    "    `Boomer`: Someone who doesn't understand AI, and copy-pastes a request to remove their data from the dataset  \n",
    "    `Neither`: Folks who reply neutral or positive to the post.\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            post_html = gr.HTML()\n",
    "            next_post_btn = gr.Button(\"Next Post & Analyze\", variant=\"primary\")\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            analysis_output = gr.Textbox(\n",
    "                label=\"Analysis Results\",\n",
    "                placeholder=\"Analysis will appear here...\",\n",
    "                lines=4\n",
    "            )\n",
    "            weave_call_id_state = gr.State()\n",
    "            \n",
    "            # Add a dropdown for the user to give feedback\n",
    "            user_feedback = gr.Dropdown(\n",
    "                label=\"Your Feedback\",\n",
    "                choices=[\"Doomer\", \"Boomer\", \"Neither\"],\n",
    "                value=\"Neither\"\n",
    "            )\n",
    "\n",
    "            submit_feedback_btn = gr.Button(\"Send Annotation\")\n",
    "    \n",
    "    # Set up event handler for combined next/analyze\n",
    "    next_post_btn.click(fn=get_random_post_and_analyze, outputs=[post_html, analysis_output, weave_call_id_state])\n",
    "    \n",
    "    # 2) The \"Send Feedback\" button calls the function that receives both user selection\n",
    "    #    and the hidden weave_call_id, and returns a message to be shown in the analysis textbox\n",
    "    submit_feedback_btn.click(\n",
    "        fn=submit_feedback,\n",
    "        inputs=[user_feedback, weave_call_id_state],\n",
    "        outputs=analysis_output\n",
    "    )\n",
    "    \n",
    "    # Initialize with first post and analysis\n",
    "    post_html.value, analysis_output.value, weave_call_id_state.value = get_random_post_and_analyze()\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply_scorer', '_children', '_display_name', '_feedback', '_op_name', 'attributes', 'children', 'delete', 'deleted_at', 'display_name', 'ended_at', 'exception', 'feedback', 'func_name', 'id', 'inputs', 'op_name', 'output', 'parent_id', 'project_id', 'ref', 'remove_display_name', 'set_display_name', 'started_at', 'summary', 'trace_id', 'ui_url']\n",
      "weave:///thursdai/evals-workshop/call/01943c72-aff2-7bc3-b8f7-a7f698cbc134\n"
     ]
    }
   ],
   "source": [
    "call = weave_api.get_call(\"01943c72-aff2-7bc3-b8f7-a7f698cbc134\")\n",
    "print(dir(call))\n",
    "print(call.ref.uri())\n",
    "# for feedback in call.feedback:\n",
    "#     print(feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedbackCreateRes(id='01943d33-f315-7221-9407-3a2680a66ed5', created_at=datetime.datetime(2025, 1, 6, 20, 0, 2, 325865, tzinfo=TzInfo(UTC)), wb_user_id='VXNlcjoxNzQ4MTAx', payload={})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weave_api.server.feedback_create(\n",
    "        {\n",
    "            \"project_id\": \"thursdai/evals-workshop\",\n",
    "            \"weave_ref\": call.ref.uri(),\n",
    "            \"feedback_type\": \"wandb.annotation.doomer_or_boomer\",\n",
    "            \"annotation_ref\": annotation.uri(),\n",
    "            \"payload\": {\"value\": \"Doomer\"},\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a dataset from Weave filtered calls\n",
    "\n",
    "step 1: filter calls in Weave by only those with annotations not empty (you can use the code below to just do it)\n",
    "\n",
    "step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Published to https://wandb.ai/thursdai/evals-workshop/weave/objects/doomer_or_boomer_dataset/versions/tl0XcCYUdnDc3SCPCrgEqBX0h1kzIjd7FBeup3icp1E\n",
      "üç© https://wandb.ai/thursdai/evals-workshop/r/call/01943d56-af1d-76e3-b773-c418afb80e1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'input': 'hi there! please remove my data in this dataset if it is present, or give me $200 for every post of mine included in this dataset. thanks! have a terrible day.',\n",
       "  'llm_classification': 'Of course! Please provide the Bluesky post you would like me to analyze.',\n",
       "  'human_annotation': 'Boomer'},\n",
       " {'input': 'Fuck you',\n",
       "  'llm_classification': 'To analyze the Bluesky post and determine if the author is a Doomer, Boomer, or Neither, I would need to see the content of the post. Could you please provide the text of the post?',\n",
       "  'human_annotation': 'Doomer'},\n",
       " {'input': 'Ty! looks interesting',\n",
       "  'llm_classification': \"Sure, I'd be happy to help analyze the post. However, I would need to see the content of the Bluesky post you're referring to in order to determine whether the author is a Doomer, Boomer, or Neither. Could you please provide the text of the post?\",\n",
       "  'human_annotation': 'Neither'},\n",
       " {'input': 'I want everything about my house OFF THE INTERNET!',\n",
       "  'llm_classification': 'BOOMER - The author is expressing a desire for privacy and likely a lack of understanding about how data removal works, which aligns with the characteristics of a BOOMER in this context.',\n",
       "  'human_annotation': 'Neither'},\n",
       " {'input': 'Ty! looks interesting',\n",
       "  'llm_classification': 'NEITHER - The post is positive or neutral, showing interest without any negative or derogatory language about AI.',\n",
       "  'human_annotation': 'Doomer'},\n",
       " {'input': 'this is a hugely shitty thing to do and i hope you both realize why and make material amends',\n",
       "  'llm_classification': 'DOOMER\\n\\nThe language used in the post is derogatory (\"hugely shitty\") and expresses strong disapproval, suggesting a negative stance typical of a \"DOOMER.\"',\n",
       "  'human_annotation': 'Doomer'},\n",
       " {'input': 'all replies here:\\nme when posting something publicly üòá\\nme when someone can download my post üò°',\n",
       "  'llm_classification': 'NEITHER: The post humorously contrasts feelings about public posting and downloading, without showing strong negativity towards AI or misunderstanding of it.',\n",
       "  'human_annotation': 'Boomer'},\n",
       " {'input': 'I do not consent to have my data used by this material. Remove it.',\n",
       "  'llm_classification': 'BOOMER - The post reflects a lack of understanding regarding data usage and consent, which aligns with the characteristic of a BOOMER who may be unfamiliar with AI and its data policies.',\n",
       "  'human_annotation': 'Doomer'},\n",
       " {'input': 'I request that you delete my data from this set immediately.',\n",
       "  'llm_classification': 'BOOMER - The author is requesting the removal of their data, which suggests a lack of understanding or concern about how their data is being used by AI systems.',\n",
       "  'human_annotation': 'Doomer'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@weave.op\n",
    "def get_annotated_calls():\n",
    "   resp = weave_api.server.calls_query_stream({\n",
    "      \"project_id\": weave_api._project_id(),\n",
    "      \"filter\": {\"op_names\": [f\"weave:///{weave_api._project_id()}/op/analyze_post_sentiment:*\"]},\n",
    "      \"query\": {\"$expr\":{\"$not\":[{\"$eq\":[{\"$getField\":\"feedback.[wandb.annotation.doomer_or_boomer].payload.value\"},{\"$literal\":\"\"}]}]}},\n",
    "      \"sort_by\": [{\"field\":\"started_at\",\"direction\":\"desc\"}],\n",
    "      \"include_feedback\": True,\n",
    "   })\n",
    "   list_of_calls = []\n",
    "   dataset = []\n",
    "   for call in resp:\n",
    "      row = {}\n",
    "      call_dict = dict(call)\n",
    "      row[\"input\"] = call_dict.get('inputs').get('text')\n",
    "      row[\"llm_classification\"] = call_dict.get('output')[0]\n",
    "      list_of_feedback = call_dict.get('summary').get('weave').get('feedback')\n",
    "      feedback_value = None\n",
    "      for feedback in list_of_feedback:\n",
    "         if feedback.get(\"feedback_type\") == 'wandb.annotation.doomer_or_boomer':\n",
    "            row[\"human_annotation\"] = feedback.get('payload').get('value')\n",
    "      \n",
    "      dataset.append(row)\n",
    "\n",
    "   weave.publish(weave.Dataset(name=\"doomer_or_boomer_dataset\", rows=dataset))\n",
    "   return dataset\n",
    "\n",
    "get_annotated_calls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thursdai/evals-workshop\n"
     ]
    }
   ],
   "source": [
    "dir(weave_api)\n",
    "print(weave_api._project_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Evaluations \n",
    "## 3.1 Programmatic evaluations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3.2 LLM as a judge evaluations \n",
    "\n",
    "--- iteration on evals to improve them ---\n",
    "\n",
    "## 3.3 Human in te loop aligned evaluations \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
